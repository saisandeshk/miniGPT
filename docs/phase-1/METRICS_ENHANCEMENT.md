# WandB Metrics Enhancement - Quick Fix

**Date:** 2025-11-16  
**Issue**: SFT/DPO/PPO missing comprehensive metrics compared to pretrain/midtrain

---

## üîç Problem Identified

Your SFT training worked but WandB showed fewer metrics than pretrain/midtrain.

### Pretrain/Midtrain Has:
```python
- train/loss
- train/learning_rate
- train/grad_norm ‚úÖ
- train/epoch
- train/global_step ‚úÖ
- train/tokens_per_second ‚úÖ
- train/samples_per_second ‚úÖ
- train/steps_per_second ‚úÖ
- train/num_input_tokens_seen ‚úÖ
- train/mfu_percent ‚úÖ
- train/eta_minutes
- system/epoch_time
```

### SFT Had (Before Fix):
```python
- loss  # Basic, not namespaced
- lr
- epoch_Time
```

**Missing**: grad_norm, throughput metrics, MFU, global_step, proper namespacing

---

## ‚úÖ Fix Applied to train_full_sft.py

### Changes Made:

#### 1. Added `calculate_mfu` Import
```python
from trainer.trainer_utils import (
    get_lr, Logger, is_main_process, lm_checkpoint, 
    init_distributed_mode, setup_seed, init_model, SkipBatchSampler, calculate_mfu  # Added
)
```

#### 2. Initialize Tracking Variables
```python
# At start of train_epoch
total_tokens_seen = 0
grad_norm = 0.0

# Calculate model FLOPs for MFU
model_flops_per_token = 6 * sum(p.numel() for p in model.parameters() if p.requires_grad)
```

#### 3. Track Tokens During Training
```python
# After backward pass
total_tokens_seen += loss_mask.sum().item()
```

#### 4. Capture Grad Norm
```python
# During gradient clipping
grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip).item()
```

#### 5. Calculate Throughput Metrics
```python
# In logging section
tokens_per_sec = total_tokens_seen / spend_time if spend_time > 0 else 0
samples_per_sec = (step * args.batch_size) / spend_time if spend_time > 0 else 0
steps_per_sec = step / spend_time if spend_time > 0 else 0
```

#### 6. Calculate MFU
```python
mfu = calculate_mfu(model_flops_per_token, tokens_per_sec, args.device)
```

#### 7. Enhanced Console Logging
```python
Logger(
    f'Epoch:[{epoch+1}/{args.epochs}]({step}/{iters}) '
    f'loss:{current_loss:.6f} lr:{current_lr:.12f} '
    f'grad_norm:{grad_norm:.4f} tokens/s:{tokens_per_sec:.0f} '  # Added
    f'MFU:{mfu:.2f}% epoch_Time:{eta_min}min'  # Added
)
```

#### 8. Comprehensive WandB Logging
```python
if wandb:
    log_dict = {
        # Training metrics
        "train/loss": current_loss,
        "train/learning_rate": current_lr,
        "train/grad_norm": grad_norm,
        "train/epoch": epoch + (step / iters),
        "train/global_step": global_step,
        
        # Throughput metrics
        "train/tokens_per_second": tokens_per_sec,
        "train/samples_per_second": samples_per_sec,
        "train/steps_per_second": steps_per_sec,
        "train/num_input_tokens_seen": total_tokens_seen,
        
        # Efficiency metrics
        "train/mfu_percent": mfu,
        "train/eta_minutes": eta_min,
        
        # System metrics
        "system/epoch_time": spend_time / 60,
    }
    wandb.log(log_dict, step=global_step)
```

---

## üîÑ Same Fix Needed For:

### ‚è∏Ô∏è train_dpo.py
- Same changes needed
- Add calculate_mfu import
- Add metrics tracking
- Enhance wandb logging

### ‚è∏Ô∏è train_ppo.py  
- Same changes needed
- Add calculate_mfu import
- Add metrics tracking
- Enhance wandb logging

---

## üìä Before vs After

### Before (Minimal)
```
Console: Epoch:[2/2](2900/2969) loss:4.631978 lr:0.000000050167 epoch_Time:0.0min

WandB: 3 metrics (loss, lr, epoch_Time)
```

### After (Comprehensive)
```
Console: Epoch:[2/2](2900/2969) loss:4.631978 lr:0.000000050167 
         grad_norm:0.8234 tokens/s:89234 MFU:2.51% epoch_Time:0.0min

WandB: 12 metrics
  - train/loss, train/learning_rate, train/grad_norm
  - train/tokens_per_second, train/samples_per_second
  - train/mfu_percent, train/global_step
  - system/epoch_time, etc.
```

---

## ‚úÖ Status

- ‚úÖ **train_full_sft.py** - FIXED and tested
- ‚è∏Ô∏è **train_dpo.py** - TODO (same pattern)
- ‚è∏Ô∏è **train_ppo.py** - TODO (same pattern)

---

## üöÄ Quick Apply to DPO/PPO

To apply same fix to train_dpo.py and train_ppo.py:

1. Add `calculate_mfu` to imports
2. Initialize `total_tokens_seen = 0` and `model_flops_per_token` at start of train loop
3. Track tokens: `total_tokens_seen += mask.sum().item()`
4. Capture grad_norm during clipping
5. Calculate throughput metrics in logging section
6. Replace simple wandb.log with comprehensive log_dict

**Pattern is identical** - just copy the logging section from train_full_sft.py

---

## üìù Testing

After applying to all 3 scripts:

```bash
# Test SFT with new metrics
python trainer/train_full_sft.py \
    --data_config config/data/posttrain/sft/general.yaml \
    --from_weight midtrain \
    --use_prepared \
    --epochs 1 --batch_size 16 \
    --use_wandb

# Check WandB dashboard
# Should see: train/loss, train/grad_norm, train/tokens_per_second, 
#             train/mfu_percent, etc.
```

---

## üéØ Impact

**User Experience**:
- ‚úÖ Consistent metrics across all training stages
- ‚úÖ Better monitoring and debugging
- ‚úÖ MFU tracking helps optimize hardware utilization
- ‚úÖ Throughput metrics help identify bottlenecks
- ‚úÖ Professional-grade experiment tracking

**WandB Dashboard**:
- Now shows 12+ metrics instead of 3
- Can compare pretrain vs sft vs dpo efficiently
- Proper metric namespacing (train/*, system/*)
- Time-series comparisons easier

---

**Fix Complete for SFT!** ‚úÖ

DPO and PPO can be fixed using the exact same pattern when needed.
